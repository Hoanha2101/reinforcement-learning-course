# Assignment 2 - Semi-gradient TD with a Neural Network

## ğŸ“œ Giá»›i thiá»‡u

Trong bÃ i táº­p trÆ°á»›c, báº¡n Ä‘Ã£ triá»ƒn khai **semi-gradient TD vá»›i State Aggregation** Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n **policy evaluation task**. Trong bÃ i táº­p nÃ y, báº¡n sáº½ triá»ƒn khai **semi-gradient TD vá»›i máº¡ng nÆ¡-ron Ä‘Æ¡n giáº£n** Ä‘á»ƒ giáº£i quyáº¿t cÃ¹ng má»™t bÃ i toÃ¡n.

Báº¡n sáº½ triá»ƒn khai má»™t agent Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ chÃ­nh sÃ¡ch cá»‘ Ä‘á»‹nh trong **500-State Randomwalk**. Má»—i táº­p (episode) báº¯t Ä‘áº§u vá»›i agent á»Ÿ tráº¡ng thÃ¡i trung tÃ¢m vÃ  káº¿t thÃºc khi agent vÆ°á»£t ra ngoÃ i biÃªn giá»›i tráº¡ng thÃ¡i 1 hoáº·c tráº¡ng thÃ¡i 500. Má»—i bÆ°á»›c, agent chá»n di chuyá»ƒn **trÃ¡i hoáº·c pháº£i vá»›i xÃ¡c suáº¥t 0.5**, vÃ  mÃ´i trÆ°á»ng xÃ¡c Ä‘á»‹nh má»©c Ä‘á»™ di chuyá»ƒn cá»§a agent.

---

## ğŸ¯ Má»¥c tiÃªu bÃ i táº­p

Trong bÃ i táº­p nÃ y, báº¡n sáº½:
- **Triá»ƒn khai phÆ°Æ¡ng phÃ¡p stochastic gradient descent** Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ trá»‹ tráº¡ng thÃ¡i.
- **Triá»ƒn khai semi-gradient TD vá»›i máº¡ng nÆ¡-ron** lÃ m bá»™ xáº¥p xá»‰ giÃ¡ trá»‹ (function approximator) vÃ  sá»­ dá»¥ng thuáº­t toÃ¡n **Adam optimizer**.
- **So sÃ¡nh hiá»‡u suáº¥t** cá»§a semi-gradient TD sá»­ dá»¥ng **máº¡ng nÆ¡-ron** vá»›i semi-gradient TD sá»­ dá»¥ng **tile-coding**.

---

## ğŸ— MÃ´i trÆ°á»ng **500-State RandomWalk**

- MÃ´i trÆ°á»ng cÃ³ **500 tráº¡ng thÃ¡i**, Ä‘Æ°á»£c Ä‘Ã¡nh sá»‘ tá»« **1 Ä‘áº¿n 500**.
- Má»—i táº­p **báº¯t Ä‘áº§u tá»« tráº¡ng thÃ¡i 250**.
- **Tráº¡ng thÃ¡i biÃªn (0 vÃ  501)** lÃ  **tráº¡ng thÃ¡i káº¿t thÃºc**:
  - Náº¿u agent **cháº¡m biÃªn trÃ¡i (state 0)**: Nháº­n pháº§n thÆ°á»Ÿng **-1**.
  - Náº¿u agent **cháº¡m biÃªn pháº£i (state 501)**: Nháº­n pháº§n thÆ°á»Ÿng **+1**.
- **HÃ nh Ä‘á»™ng:**
  - Agent cÃ³ thá»ƒ di chuyá»ƒn **trÃ¡i hoáº·c pháº£i vá»›i xÃ¡c suáº¥t 0.5**.
  - Khi Ä‘i **trÃ¡i**, agent ngáº«u nhiÃªn Ä‘áº¿n má»™t trong **100 tráº¡ng thÃ¡i bÃªn trÃ¡i**.
  - Khi Ä‘i **pháº£i**, agent ngáº«u nhiÃªn Ä‘áº¿n má»™t trong **100 tráº¡ng thÃ¡i bÃªn pháº£i**.
  - Náº¿u agent gáº§n biÃªn, xÃ¡c suáº¥t cháº¡m biÃªn sáº½ cao hÆ¡n (vÃ­ dá»¥: tá»« state 50, Ä‘i trÃ¡i cÃ³ xÃ¡c suáº¥t 50% cháº¡m biÃªn).

---

## ğŸ“¦ ThÆ° viá»‡n sá»­ dá»¥ng

BÃ i táº­p nÃ y sá»­ dá»¥ng cÃ¡c thÆ° viá»‡n sau:
- **numpy**: ThÆ° viá»‡n toÃ¡n há»c cho Python.
- **matplotlib**: Há»— trá»£ váº½ Ä‘á»“ thá»‹ káº¿t quáº£.
- **RL-Glue**: Framework Ä‘á»ƒ cháº¡y cÃ¡c thÃ­ nghiá»‡m Reinforcement Learning.
- **tqdm**: Hiá»ƒn thá»‹ thanh tiáº¿n trÃ¬nh khi huáº¥n luyá»‡n.
- **BaseOptimizer**: Lá»›p trá»«u tÆ°á»£ng cho API tá»‘i Æ°u hÃ³a cá»§a Agent.
- **plot_script**: Táº­p lá»‡nh Ä‘á»ƒ hiá»ƒn thá»‹ káº¿t quáº£.
- **RandomWalkEnvironment**: MÃ´i trÆ°á»ng 500-State RandomWalk tá»« Assignment 1.

**âš ï¸ LÆ°u Ã½ quan trá»ng:**
- **KhÃ´ng nháº­p thÃªm thÆ° viá»‡n khÃ¡c**, vÃ¬ Ä‘iá»u nÃ y cÃ³ thá»ƒ lÃ m há»ng bá»™ cháº¥m Ä‘iá»ƒm tá»± Ä‘á»™ng.
- **LÃ m theo Ä‘Ãºng trÃ¬nh tá»± cÃ¡c Ã´ mÃ£** Ä‘á»ƒ Ä‘áº£m báº£o thuáº­t toÃ¡n hoáº¡t Ä‘á»™ng chÃ­nh xÃ¡c.

---

## ğŸ“Œ Ghi chÃº
- **Máº¡ng nÆ¡-ron** Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° má»™t **function approximator**, giÃºp **tá»•ng quÃ¡t hÃ³a (generalization)** khi sá»‘ lÆ°á»£ng tráº¡ng thÃ¡i lá»›n.
- **Adam optimizer** giÃºp cáº­p nháº­t trá»ng sá»‘ máº¡ng nhanh chÃ³ng vÃ  á»•n Ä‘á»‹nh.
- **So sÃ¡nh vá»›i Tile Coding** sáº½ giÃºp báº¡n hiá»ƒu rÃµ lá»£i Ã­ch cá»§a tá»«ng phÆ°Æ¡ng phÃ¡p trong viá»‡c xáº¥p xá»‰ giÃ¡ trá»‹ tráº¡ng thÃ¡i.

---

## ğŸ“œ Báº£n quyá»n
BÃ i táº­p nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn dá»±a trÃªn cÃ¡c tÃ i liá»‡u vá» **Reinforcement Learning** cá»§a **Richard Sutton**.

